{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gMnY4ESvfEA"
   },
   "source": [
    "# HPC as a solution for AI: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wHXE1ij1bIA"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this section, it will be shown how to optimize PyTorch models, accelerating training and execution using GPUs.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principal gols are:\n",
    "* **Use** the PyTorch library on GPU environments for the first time to accelerate the training of image classification models,\n",
    "* **Familiarize** yourself with the CIFAR-10 and CIFAR-100 dataset by classifying their various classes,\n",
    "* **Evaluate** and **Compare** the performance of your models on GPU and CPU environments to understand the benefits of GPU acceleration in AI tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmwBTXpn1bIA"
   },
   "source": [
    "## The problem: Resource-intensive training and model scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP0wr4R51bIA"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "As AI research progresses, deep neural networks have become critical for tasks like image generation and language translation. However, resource-intensive training challenges arise as networks become more complex and demanding in performance.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Research and development in artificial intelligence have made remarkable strides in recent decades, mainly driven by deep neural networks. These networks are computational structures loosely inspired by the functioning of the human brain. They are particularly well-suited for tasks that involve large volumes of data, such as pattern recognition in images, natural language processing, and more.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "However, as the problems being addressed become more complex and performance demands increase, the need for computational resources also grows exponentially. Additionally, the scalability of these models becomes a concern as they grow in size and complexity. Maintaining and optimizing constantly expanding AI models becomes challenging for the research and development community.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4Teb2m1bIA"
   },
   "source": [
    "## The solution: GPUs and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST3ronAy1bIA"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "Using libraries like PyTorch, a popular machine learning and AI framework, offers a flexible interface for designing, training, and evaluating neural networks using GPUs, especially when harnessed with computational prowess.\n",
    "</p>\n",
    "<p style='text-align: justify;'>\n",
    "Furthermore, Intel® PyTorch is well equipped to fully utilize the optimizations and hardware support of Intel® processors and GPUs. This synergy results in an even more efficient and performance-oriented machine-learning experience. It enables practitioners to extract maximum computational throughput from their hardware infrastructure.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "##  ☆ Challenge: Zoo breakout!☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    Recently, an unexpected incident occurred at the local zoo, <b>Orange Grove Zoo</b>: all the animals escaped from their enclosures and are now roaming freely. To deal with this situation, we need your help locating and classifying the escaped animals, distinguishing each animal class, and identifying possible vehicles in the same environment.\n",
    "</p>\n",
    "<p style='text-align: justify;'> \n",
    "You have been assigned as the person responsible for developing a computer vision system capable of identifying and classifying the escaped animals and identifying the presence of vehicles in the images. We will use the CIFAR-10 dataset and the TensorFlow library to train a deep-learning model for this challenge.\n",
    "</p>\n",
    "CIFAR-10 and CIFAR-100 datasets comprehensively collect $32$x$32$ pixel images grouped into $10$ distinct classes.\n",
    "\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-10 consists of $60,000$ images, each belonging to one of the ten classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. This dataset offers a diverse set of images representing everyday objects.\n",
    "\n",
    "- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-100 expands upon the CIFAR-10 concept, containing 60,000 images as well. However, it introduces a more challenging task by categorizing images into 100 classes. These classes include various subcategories such as fruits, animals, vehicles, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9pJ2tDOCaN6"
   },
   "source": [
    "a) **Create** deep neural network model utilizing the PyTorch library for the classification of animals and vehicles on a GPU environment using the CIFAR-10 dataset.\n",
    "\n",
    "b) **Conduct** a comparative analysis between models trained on a CPU and GPU to highlight disparities in results.\n",
    "\n",
    "c) Now, use the CIFAR-100 dataset for the classification of animals and vehicles on a GPU. Would it be a good decision to use a GPU or CPU environment for the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆  Solution for `CIFAR-10` using PyTorch on GPU  ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Define processing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Transformations to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the data preparation process, we create a ```transforms``` object to apply specific transformations to the data. These transformations are commonly used in training datasets to enhance data diversity and ready images for utilization in a deep learning model, such as a convolutional neural network (CNN). I will provide a detailed explanation of each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, download the CIFAR-10 dataset and load it into the code. Define the neural network as we have done in previous notebooks, and remember to move this network instance to the previously defined device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "gpu_start_time = time.time()\n",
    "\n",
    "for epoch in range(10):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "gpu_end_time = time.time()\n",
    "\n",
    "print(f'GPU Training time: {gpu_end_time - gpu_start_time}')\n",
    "\n",
    "torch.save(net.state_dict(), 'cifar10_gpu_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆  Solution for `CIFAR-100` using PyTorch on GPU  ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9Ud6RMBwAC2"
   },
   "source": [
    "#### ⊗ Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yZjcPbwQwAC2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xX9OzqeRwAC3"
   },
   "source": [
    "#### ⊗ Define processing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "in_dL7qiwAC3"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t67WI7bSwAC3"
   },
   "source": [
    "#### ⊗ Transformations to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjNEfd_hwAC3"
   },
   "source": [
    "As part of the data preparation process, we create a ```transforms``` object to apply specific transformations to the data. These transformations are commonly used in training datasets to enhance data diversity and ready images for utilization in a deep learning model, such as a convolutional neural network (CNN). I will provide a detailed explanation of each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VqrPy46pwAC3"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qacjkiEGwAC4"
   },
   "source": [
    "Following that, download the CIFAR-10 dataset and load it into the code. Define the neural network as we have done in previous notebooks, and remember to move this network instance to the previously defined device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DidyB70kwAC4",
    "outputId": "2a85c69f-228e-42f8-e434-cf346f2d4914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN6p-GqvwAC4"
   },
   "source": [
    "#### ⊗ Training the network for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPhkUlBuwAC4",
    "outputId": "d1c7e4e1-3fbb-4a9c-82ad-e9ab7744c430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7846233637436577\n",
      "Epoch 2, Loss: 1.417086196067693\n",
      "Epoch 3, Loss: 1.232096059090646\n",
      "Epoch 4, Loss: 1.1051897074255492\n",
      "Epoch 5, Loss: 1.012491160951307\n",
      "Epoch 6, Loss: 0.9322243309996622\n",
      "Epoch 7, Loss: 0.8707111179066436\n",
      "Epoch 8, Loss: 0.8234430559151008\n",
      "Epoch 9, Loss: 0.7852854505371865\n",
      "Epoch 10, Loss: 0.7453446917216796\n",
      "GPU Training time: 72.81169199943542\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "gpu_start_time = time.time()\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "gpu_end_time = time.time()\n",
    "\n",
    "print(f'GPU Training time: {gpu_end_time - gpu_start_time}')\n",
    "\n",
    "torch.save(net.state_dict(), 'cifar10_gpu_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFKsxPAEwAC5"
   },
   "source": [
    "#### ⊗ Training the network for CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8zX7lXBwAC5"
   },
   "source": [
    "Using the CIFAR-100 dataset for the classification of animals and vehicles is a more computationally intensive task than CIFAR-10 training. This is because of the larger number of images and classes. You will also need more epochs to properly train the model, especially if you are training a deep neural network for this purpose. Using a GPU is a good decision if you have access to one, as it will significantly speed up the training process and enable you to experiment with more complex models and larger datasets in the future. So, let's repeat the process, this time loading the CIFAR-100 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "xWTIejQKwAC5",
    "outputId": "b884de21-aa3d-41f2-8685-a95b850bb311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 1, Loss: 4.159843230796287\n",
      "Epoch 2, Loss: 3.5960702987583093\n",
      "Epoch 3, Loss: 3.292882069907225\n",
      "Epoch 4, Loss: 3.075037962945221\n",
      "Epoch 5, Loss: 2.907633927167224\n",
      "Epoch 6, Loss: 2.757825186795286\n",
      "Epoch 7, Loss: 2.617540892432718\n",
      "Epoch 8, Loss: 2.485402060286773\n",
      "Epoch 9, Loss: 2.3836793936122103\n",
      "Epoch 10, Loss: 2.291313350657978\n",
      "Epoch 11, Loss: 2.2199832243687663\n",
      "Epoch 12, Loss: 2.143865962162652\n",
      "Epoch 13, Loss: 2.0762993393041898\n",
      "Epoch 14, Loss: 2.011141384044267\n",
      "Epoch 15, Loss: 1.9460219605194637\n",
      "Epoch 16, Loss: 1.8963490090406765\n",
      "Epoch 17, Loss: 1.8364502542159136\n",
      "Epoch 18, Loss: 1.7872820312104871\n",
      "Epoch 19, Loss: 1.7442081575198551\n",
      "Epoch 20, Loss: 1.6870001713028344\n",
      "Epoch 21, Loss: 1.6629252330116604\n",
      "Epoch 22, Loss: 1.6107358831883696\n",
      "Epoch 23, Loss: 1.5728981830274966\n",
      "Epoch 24, Loss: 1.5394339909029129\n",
      "Epoch 25, Loss: 1.5030857821559662\n",
      "Epoch 26, Loss: 1.4581448005898225\n",
      "Epoch 27, Loss: 1.4291300546482701\n",
      "Epoch 28, Loss: 1.394023850140974\n",
      "Epoch 29, Loss: 1.3684600931604196\n",
      "Epoch 30, Loss: 1.332746690648901\n",
      "Epoch 31, Loss: 1.3090644471175836\n",
      "Epoch 32, Loss: 1.2715033343076096\n",
      "Epoch 33, Loss: 1.2547301837550404\n",
      "Epoch 34, Loss: 1.2252727917698034\n",
      "Epoch 35, Loss: 1.1859884156900293\n",
      "Epoch 36, Loss: 1.170688822446272\n",
      "Epoch 37, Loss: 1.1286144825198767\n",
      "Epoch 38, Loss: 1.1158985899537421\n",
      "Epoch 39, Loss: 1.1029103309906962\n",
      "Epoch 40, Loss: 1.0737053442489155\n",
      "Epoch 41, Loss: 1.0556818324586619\n",
      "Epoch 42, Loss: 1.0256708188130117\n",
      "Epoch 43, Loss: 1.0022312055158493\n",
      "Epoch 44, Loss: 0.9779943099717046\n",
      "Epoch 45, Loss: 0.9652564118585318\n",
      "Epoch 46, Loss: 0.9510458837384763\n",
      "Epoch 47, Loss: 0.9274287432660837\n",
      "Epoch 48, Loss: 0.9123095716052043\n",
      "Epoch 49, Loss: 0.8963021789975179\n",
      "Epoch 50, Loss: 0.8730774994396493\n",
      "Epoch 51, Loss: 0.8561079053927565\n",
      "Epoch 52, Loss: 0.8405062595901587\n",
      "Epoch 53, Loss: 0.8174253924728354\n",
      "Epoch 54, Loss: 0.8093934702446394\n",
      "Epoch 55, Loss: 0.7923939627454714\n",
      "Epoch 56, Loss: 0.7832355779760024\n",
      "Epoch 57, Loss: 0.7608444070267251\n",
      "Epoch 58, Loss: 0.7437894996779654\n",
      "Epoch 59, Loss: 0.733228798717489\n",
      "Epoch 60, Loss: 0.733753025455548\n",
      "Epoch 61, Loss: 0.7115981661907548\n",
      "Epoch 62, Loss: 0.705375822989837\n",
      "Epoch 63, Loss: 0.6842099935045023\n",
      "Epoch 64, Loss: 0.6761628115725944\n",
      "Epoch 65, Loss: 0.6570139718635003\n",
      "Epoch 66, Loss: 0.651298717921957\n",
      "Epoch 67, Loss: 0.6336978640397797\n",
      "Epoch 68, Loss: 0.6314109496753234\n",
      "Epoch 69, Loss: 0.6234727157351306\n",
      "Epoch 70, Loss: 0.6089842452874878\n",
      "Epoch 71, Loss: 0.6070396523646382\n",
      "Epoch 72, Loss: 0.5871822887369434\n",
      "Epoch 73, Loss: 0.5836366729815597\n",
      "Epoch 74, Loss: 0.5606236534807688\n",
      "Epoch 75, Loss: 0.5639920036125061\n",
      "Epoch 76, Loss: 0.5570701513906269\n",
      "Epoch 77, Loss: 0.5547570218058193\n",
      "Epoch 78, Loss: 0.5284249815337189\n",
      "Epoch 79, Loss: 0.5292038534913222\n",
      "Epoch 80, Loss: 0.5167182167167859\n",
      "Epoch 81, Loss: 0.5153254349060985\n",
      "Epoch 82, Loss: 0.5151344773257175\n",
      "Epoch 83, Loss: 0.4997142859355873\n",
      "Epoch 84, Loss: 0.5004227830625861\n",
      "Epoch 85, Loss: 0.49226399558736844\n",
      "Epoch 86, Loss: 0.48758400637475424\n",
      "Epoch 87, Loss: 0.4820257773256058\n",
      "Epoch 88, Loss: 0.47611792625673593\n",
      "Epoch 89, Loss: 0.4628236610490038\n",
      "Epoch 90, Loss: 0.4614302916142642\n",
      "Epoch 91, Loss: 0.46167359533517255\n",
      "Epoch 92, Loss: 0.45864417348676323\n",
      "Epoch 93, Loss: 0.43839955695754734\n",
      "Epoch 94, Loss: 0.4376074103519435\n",
      "Epoch 95, Loss: 0.445832291489367\n",
      "Epoch 96, Loss: 0.4349825027424966\n",
      "Epoch 97, Loss: 0.4153297855649763\n",
      "Epoch 98, Loss: 0.4133551801028459\n",
      "Epoch 99, Loss: 0.4091139658332786\n",
      "Epoch 100, Loss: 0.40164986046988643\n",
      "CPU Training time: 1721.766683101654\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Change CIFAR10 to CIFAR100\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        # Change output layers to 100 units\n",
    "        self.fc2 = nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "gpu_start_time = time.time()\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "gpu_end_time = time.time()\n",
    "\n",
    "print(f'CPU Training time: {gpu_end_time - gpu_start_time}')\n",
    "\n",
    "# Save the model é CIFAR100\n",
    "torch.save(net.state_dict(), 'cifar100_gpu_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "We explored training neural networks with PyTorch, comparing CPU and GPU performance on the CIFAR-10 dataset. When utilizing the CPU environment, the process can be executed in approximately <b>811 seconds or (13.52 minutes)</b>. However, when employed in the GPU environment with PyTorch, the execution time was reduced to approximately <b>191 seconds or (3.2 minutes)</b>. This outcome illustrates that the GPU has achieved nearly a <b>Speedup of 4X</b> compared to the CPU when running with 10 epochs. Thanks to its parallel computing capabilities, the GPU has substantially enhanced the training speed, which is particularly advantageous for handling extensive data and intricate models in deep learning.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCCcZ7Q31bIC"
   },
   "source": [
    "## Summary\n",
    "In this notebook we have shown: \n",
    "\n",
    "- Install and use PyTorch using GPU environments,\n",
    "- Comparative performance tests between CPU and GPU on model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FolLqE_1bID"
   },
   "source": [
    "## Clear the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXiePpX31bID"
   },
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMB90WpX1bID"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbgrxWUP1bIE"
   },
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RniCDPdQ1bIE"
   },
   "source": [
    "Congratulations on finishing the HPC simulations topic!! You have completed the last part of the learning objectives of this part of the course! As a final exercise, complete an applied problem in the assessment in [_04-hpc-simulations-assessment.ipynb_](04-hpc-simulations-assessment.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
