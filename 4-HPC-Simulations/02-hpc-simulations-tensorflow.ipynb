{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9712f6e",
   "metadata": {},
   "source": [
    "# HPC as solutions for AI: TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca98a4",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this section, it will be shown how to optimize TensorFlow models, accelerating training and execution using GPUs.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a80bd-2076-4834-ad32-588e2424d4a4",
   "metadata": {},
   "source": [
    "The principal goals are:\n",
    "* **Understand** what is TensorFlow,\n",
    "* **Learn** the basic concepts of TensorFlow for GPUs,\n",
    "* **Familiarize** yourself with the CIFAR-10 and CIFAR-100 datasets by classifying their various classes,\n",
    "* **Create** a model using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519cfc5",
   "metadata": {},
   "source": [
    "## What applications uses TensorFlow in AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90331c7b",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "TensorFlow is an open-source machine learning framework developed by Google that is widely used in artificial intelligence (AI) applications. It provides a comprehensive set of tools, libraries, and community support for building and deploying various machine learning models, such as deep learning, computer vision, and neural networks. Overall, TensorFlow is a versatile framework that covers a wide range of machine learning and AI applications. However, when creating a model, the training process becomes a bottleneck as it takes a lot of time, but as we will see throughout the module, TensorFlow allows us to speed up this processing.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7b378",
   "metadata": {},
   "source": [
    "## The solution: GPUs and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fddc371",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "In addition to being a powerful library for machine learning, TensorFlow allows you to train the created model using GPUs, enhancing and accelerating the training process. As we will see later, the performance gain when training a TensorFlow model on a GPU is enormous because GPUs are designed with thousands of processing cores, which allow the execution of many simultaneous operations. This is especially beneficial for matrix calculations, which are fundamental in machine learning algorithms such as neural networks.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf4e20-c662-4b55-afb1-3a72692d53b7",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "##  ☆ Challenge: Zoo breakout!☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a32ad3-6702-49ec-b03e-dd5f6be83cd1",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    Recently, an unexpected incident occurred at the local zoo, <b>Orange Grove Zoo</b>: all the animals escaped from their enclosures and are now roaming freely. To deal with this situation, we need your help locating and classifying the escaped animals, distinguishing each animal class, and identifying possible vehicles in the same environment.\n",
    "</p>\n",
    "<p style='text-align: justify;'> \n",
    "You have been assigned as the person responsible for developing a computer vision system capable of identifying and classifying the escaped animals and identifying the presence of vehicles in the images. We will use the CIFAR-10 dataset and the TensorFlow library to train a deep-learning model for this challenge.\n",
    "</p>\n",
    "CIFAR-10 and CIFAR-100 datasets comprehensively collect $32$x$32$ pixel images grouped into $10$ distinct classes.\n",
    "\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-10 consists of $60,000$ images, each belonging to one of the ten classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. This dataset offers a diverse set of images representing everyday objects.\n",
    "\n",
    "- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-100 expands upon the CIFAR-10 concept, containing 60,000 images as well. However, it introduces a more challenging task by categorizing images into 100 classes. These classes include various subcategories such as fruits, animals, vehicles, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac15552-86f2-42e2-a62d-ad0b875d46a0",
   "metadata": {
    "id": "X9pJ2tDOCaN6"
   },
   "source": [
    "a) **Create** deep neural network model utilizing the TensorFlow library for the classification of animals and vehicles on a GPU environment using the CIFAR-10 dataset.\n",
    "\n",
    "b) **Conduct** a comparative analysis between models trained on a CPU and GPU to highlight disparities in results.\n",
    "\n",
    "c) Now, use the CIFAR-100 dataset for the classification of animals and vehicles on a GPU. Would it be a good decision to use a GPU or CPU environment for the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3fab8-7a7d-4977-aa9f-3fbc73eb5ec0",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution for `CIFAR-10` using TensorFlow on CPU and GPU ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983edbde",
   "metadata": {},
   "source": [
    "#### ⊗ Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f0f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:35:19.729161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 20:35:20.360143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fc965",
   "metadata": {},
   "source": [
    "#### ⊗ Verify the devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d046e",
   "metadata": {},
   "source": [
    "It is very important, before trying to execute anything on any device, to verify if it is available and if TensorFlow can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5ad9f",
   "metadata": {},
   "source": [
    "#####  Checking the environmental availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49480c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU device:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "GPU device:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:35:21.355158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:21.381995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:21.382197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "print(f\"CPU device: \", tf.config.list_physical_devices('CPU'))\n",
    "print(f\"GPU device: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adb41f",
   "metadata": {},
   "source": [
    "#### ⊗ Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d0b28",
   "metadata": {},
   "source": [
    "Now we need to download the CIFAR-10 dataset to be able to make predictions. This dataset is a set of labeled images, meaning that each image already has a known label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c34a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2746c",
   "metadata": {},
   "source": [
    "#### ⊗ Normalizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c993dd",
   "metadata": {},
   "source": [
    "After downloading the entire set of images, we need to normalize them so that we can use them in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07245e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing pixel values to the [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136107e",
   "metadata": {},
   "source": [
    "#### ⊗ Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a977c7",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    " Below we have the training function with model creation and model compilation. Notice that we need to do the creation and compilation together with the training because we need to set in which device everything will be done. We need to do this because if we don't set the device to create and compile the model, the TensorFlow will choose the faster device, in this case, the GPU, so if we try to use the CPU to train the model, it will fail because the model will be created on the GPU. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375da0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, train_images, train_labels):\n",
    "    with tf.device(device):\n",
    "        \n",
    "        # Creating the CNN model\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(train_images, train_labels, epochs=10, \n",
    "                            validation_data=(test_images, test_labels), verbose=1)\n",
    "        end_time = time.time()\n",
    "    \n",
    "    return history, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb719ac8",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> The next step is to perform the model training. Note that in the step below, we will use the CPU to train the model and then the GPU to train and compare their execution times. (Depending on the GPU and CPU of your machine, this step may take some time). </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a0eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:35:22.017197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:22.017452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:22.017646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:22.086725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:22.086923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:22.087076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 20:35:22.087190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9690 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:35:22.566696: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  28/1563 [..............................] - ETA: 8s - loss: 2.2819 - accuracy: 0.1183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:35:23.446930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f27b000a430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-13 20:35:23.447049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-13 20:35:23.453681: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-13 20:35:23.475873: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5416 - accuracy: 0.4365 - val_loss: 1.2468 - val_accuracy: 0.5525\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1632 - accuracy: 0.5897 - val_loss: 1.0588 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9986 - accuracy: 0.6506 - val_loss: 0.9838 - val_accuracy: 0.6548\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9014 - accuracy: 0.6847 - val_loss: 0.9313 - val_accuracy: 0.6722\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8311 - accuracy: 0.7099 - val_loss: 0.9214 - val_accuracy: 0.6794\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7761 - accuracy: 0.7280 - val_loss: 0.8863 - val_accuracy: 0.6965\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7254 - accuracy: 0.7454 - val_loss: 0.9109 - val_accuracy: 0.6872\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6862 - accuracy: 0.7581 - val_loss: 0.8779 - val_accuracy: 0.7028\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6496 - accuracy: 0.7725 - val_loss: 0.8577 - val_accuracy: 0.7059\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6086 - accuracy: 0.7871 - val_loss: 0.8543 - val_accuracy: 0.7192\n",
      "\n",
      "CPU Training time: 100.12 seconds or (1.67 minutes)\n"
     ]
    }
   ],
   "source": [
    "history, cpu_time = train_model('/CPU:0', train_images, train_labels)\n",
    "print(f\"\\nCPU Training time: {cpu_time:.2f} seconds or ({cpu_time / 60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c694e7d",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Now let's do the same process, but now with the GPU </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "279b2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:37:02.871275: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2023-11-13 20:37:03.461766: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:37:04.112846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-11-13 20:37:04.177134: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-13 20:37:04.266971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-13 20:37:04.289473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f238ab55dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-13 20:37:04.289491: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-11-13 20:37:04.334874: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 2ms/step - loss: 1.5067 - accuracy: 0.4482 - val_loss: 1.3153 - val_accuracy: 0.5302\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1439 - accuracy: 0.5926 - val_loss: 1.0769 - val_accuracy: 0.6196\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.9955 - accuracy: 0.6474 - val_loss: 1.0245 - val_accuracy: 0.6367\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8976 - accuracy: 0.6863 - val_loss: 0.9755 - val_accuracy: 0.6578\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8249 - accuracy: 0.7090 - val_loss: 0.9003 - val_accuracy: 0.6840\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7716 - accuracy: 0.7289 - val_loss: 0.8546 - val_accuracy: 0.7026\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7252 - accuracy: 0.7468 - val_loss: 0.8799 - val_accuracy: 0.7051\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6826 - accuracy: 0.7598 - val_loss: 0.8354 - val_accuracy: 0.7156\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6421 - accuracy: 0.7742 - val_loss: 0.8971 - val_accuracy: 0.7030\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6066 - accuracy: 0.7850 - val_loss: 0.8867 - val_accuracy: 0.7030\n",
      "\n",
      "GPU Training time: 33.99 seconds or (0.57 minutes)\n"
     ]
    }
   ],
   "source": [
    "gpu_history, gpu_time = train_model('/GPU:0', train_images, train_labels)\n",
    "print(f\"\\nGPU Training time: {gpu_time:.2f} seconds or ({gpu_time / 60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1f900",
   "metadata": {},
   "source": [
    "Now we will evaluate the speedup by comparing the GPU and CPU execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ab42b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speedup: 2.95X\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSpeedup:{cpu_time / gpu_time: .2f}X\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64666e10-02ff-4d6c-aa01-5b07f8d839d6",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution `CIFAR-100` using TensorFlow on CPU and GPU ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b516ea9-f290-48f3-9a1c-1d27dfe8fc40",
   "metadata": {},
   "source": [
    "#### ⊗ Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957c8134-f1af-461f-bcb6-04bf6fd3df37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febc504-4ebe-4bb6-8f6c-c824026d568e",
   "metadata": {},
   "source": [
    "#### ⊗ Verify the devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df68d65-eaf6-4410-8ac1-1966b6b807c9",
   "metadata": {},
   "source": [
    "It is very important, before trying to execute anything on any device, to verify if it is available and if TensorFlow can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952650d-c543-4377-80d8-9acc349847d1",
   "metadata": {},
   "source": [
    "#####  Checking the environmental availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f562ecf4-18ab-4d8e-9069-f5ae649c35c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU device:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "GPU device:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "print(f\"CPU device: \", tf.config.list_physical_devices('CPU'))\n",
    "print(f\"GPU device: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231953fc-3a5a-4815-9bb9-e36da4ee6c03",
   "metadata": {},
   "source": [
    "#### ⊗ Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e871e-c674-45bc-80f0-95b92eacc173",
   "metadata": {},
   "source": [
    "Now we need to download the CIFAR-100 dataset to be able to make predictions. This dataset is a labeled images, meaning that each image to be loaded already has a known label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66dc3ef2-a385-4e4b-bc61-9338eac7733d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the CIFAR-100 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea90a61-5c93-4ab2-8881-9333d4a7eced",
   "metadata": {},
   "source": [
    "#### ⊗ Normalizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa4126-0a2c-45b6-b93c-0912581f20d0",
   "metadata": {},
   "source": [
    "After downloading the entire set of images, we need to normalize them so that we can use them in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d97aba15-fe1c-463a-814c-df82daa15b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing pixel values to the [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e061fe0-da7a-4e34-912e-29b17212eb34",
   "metadata": {},
   "source": [
    "#### ⊗ Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7451a-a8e4-46b5-8f11-cf50e8051030",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    " Below we have the training function with model creation and model compilation. Notice that we need to get the creation and compilation together with the training because we need to set in which device everything will be done. We need to do this because if we don't set the device to create and compile the model, the TensorFlow will choose the faster device, in this case, the GPU, so if we try to use the CPU to train the model, it will fail because the model will be created on the GPU. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e269f4-3312-47a8-a4a8-876b5244f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, train_images, train_labels):\n",
    "    with tf.device(device):\n",
    "        # Creating the CNN model\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(100)\n",
    "        ])\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(train_images, train_labels, epochs=10, \n",
    "                            validation_data=(test_images, test_labels), verbose=1)\n",
    "        end_time = time.time()\n",
    "    \n",
    "    return history, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b4655-aaa5-48c9-84de-e8c6c4bbe4a1",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    The next step is to train the model. Note that in the step below we will use the CPU to train the model. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39d66c50-1b15-4115-8312-04e4705af6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:37:37.636772: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.9979 - accuracy: 0.0868 - val_loss: 3.5288 - val_accuracy: 0.1664\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.3353 - accuracy: 0.1944 - val_loss: 3.2283 - val_accuracy: 0.2265\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.0427 - accuracy: 0.2487 - val_loss: 3.0120 - val_accuracy: 0.2642\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.8596 - accuracy: 0.2858 - val_loss: 2.8827 - val_accuracy: 0.2887\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.7244 - accuracy: 0.3123 - val_loss: 2.8172 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.6163 - accuracy: 0.3346 - val_loss: 2.7862 - val_accuracy: 0.3055\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.5276 - accuracy: 0.3537 - val_loss: 2.7169 - val_accuracy: 0.3218\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.4409 - accuracy: 0.3696 - val_loss: 2.6487 - val_accuracy: 0.3378\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3663 - accuracy: 0.3862 - val_loss: 2.6384 - val_accuracy: 0.3345\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3038 - accuracy: 0.3994 - val_loss: 2.6054 - val_accuracy: 0.3470\n",
      "\n",
      "CPU Training time: 103.07 seconds or (1.72 minutes)\n"
     ]
    }
   ],
   "source": [
    "cpu_history, cpu_time = train_model('/CPU:0', train_images, train_labels)\n",
    "print(f\"\\nCPU Training time: {cpu_time:.2f} seconds or ({cpu_time / 60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020138db-d31a-4065-99ad-574da599db9e",
   "metadata": {},
   "source": [
    "Now we will perform the same training only using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a08c023-228b-4ded-86ac-656aa008649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:39:20.910500: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 3.9430 - accuracy: 0.0961 - val_loss: 3.4656 - val_accuracy: 0.1794\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 3.2907 - accuracy: 0.2041 - val_loss: 3.1364 - val_accuracy: 0.2365\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 3.0085 - accuracy: 0.2555 - val_loss: 2.9359 - val_accuracy: 0.2713\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.8207 - accuracy: 0.2943 - val_loss: 2.8319 - val_accuracy: 0.2938\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.6812 - accuracy: 0.3216 - val_loss: 2.8160 - val_accuracy: 0.2990\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.5816 - accuracy: 0.3439 - val_loss: 2.6831 - val_accuracy: 0.3248\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.4939 - accuracy: 0.3606 - val_loss: 2.6279 - val_accuracy: 0.3392\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.4159 - accuracy: 0.3755 - val_loss: 2.6662 - val_accuracy: 0.3341\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3447 - accuracy: 0.3902 - val_loss: 2.6089 - val_accuracy: 0.3418\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.2905 - accuracy: 0.4013 - val_loss: 2.6143 - val_accuracy: 0.3389\n",
      "\n",
      "GPU Training time: 33.96 seconds or (0.57 minutes)\n"
     ]
    }
   ],
   "source": [
    "gpu_history, gpu_time = train_model('/GPU:0', train_images, train_labels)\n",
    "print(f\"\\nGPU Training time: {gpu_time:.2f} seconds or ({gpu_time / 60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd2cc5-78a3-4c2b-80d3-f05113f4b505",
   "metadata": {},
   "source": [
    "Now we will evaluate the speedup by comparing the GPU and CPU execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4b3db5c-af0f-4f09-86fe-ecf23de9d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speedup: 3.04X\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSpeedup:{cpu_time / gpu_time: .2f}X\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3689f6-fd46-4d9f-b72e-651ad7d3f4fb",
   "metadata": {},
   "source": [
    "### Comments about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf1b32",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "We explored training neural networks with TensorFlow, comparing CPU and GPU performance on the CIFAR-10 and CIFAR-100 dataset using 10 epochs. When training with CIFAR-10 and utilizing the CPU, and GPU environments, the process can be executed in approximately (in seconds):\n",
    "</p>\n",
    "\n",
    "|  TensorFlow |      CIFAR-10    |  CIFAR-100 |\n",
    "|----------|:-------------:      |-----------:|\n",
    "| CPU         |  100.11          |   103.07|\n",
    "| GPU         |  33.99           |   33.96 |\n",
    "| Speedup     |  2.95X           |   3.04 |\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "This outcome illustrates that the GPU has achieved nearly a <b>Speedup of 3X</b> compared to the CPU when running with 10 epochs in the algorithm with the highest computational cost (CIFAR-100). Thanks to its parallel computing capabilities, the GPU has substantially enhanced the training speed, which is particularly advantageous for handling extensive data and intricate models in deep learning.\n",
    "</p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f43b0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook we have shown: \n",
    "\n",
    "- Install and use TensorFlow using GPU environments,\n",
    "- Comparative performance tests between CPU and GPU on model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e8dad",
   "metadata": {},
   "source": [
    "## Clear the memory\n",
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3945a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52915-f34b-480a-ac98-dc48f82bd007",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebb05e",
   "metadata": {},
   "source": [
    "In this section, you learned how to use TensorFlow in a simple example using a GPU environment. In the next section, you will learn about other applications in which those devices can be pretty useful, in the notebbok [_03-hpc-simulations-pytorch.ipynb_](03-hpc-simulations-pytorch.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
