{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9712f6e",
   "metadata": {},
   "source": [
    "# HPC as solutions for AI: TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca98a4",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this section, it will be shown how to optimize TensorFlow models, accelerating training and execution using GPUs.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a80bd-2076-4834-ad32-588e2424d4a4",
   "metadata": {},
   "source": [
    "The principal goals are:\n",
    "* **Understand** what is TensorFlow,\n",
    "* **Learn** the basic concepts of TensorFlow for GPUs,\n",
    "* **Familiarize** yourself with the CIFAR-10 and CIFAR-100 datasets by classifying their various classes,\n",
    "* **Create** a model using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519cfc5",
   "metadata": {},
   "source": [
    "## What applications uses TensorFlow in AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90331c7b",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "TensorFlow is an open-source machine learning framework developed by Google that is widely used in artificial intelligence (AI) applications. It provides a comprehensive set of tools, libraries, and community support for building and deploying various machine learning models, such as deep learning, computer vision, and neural networks. Overall, TensorFlow is a versatile framework that covers a wide range of machine learning and AI applications. However, when creating a model, the training process becomes a bottleneck as it takes a lot of time, but as we will see throughout the module, TensorFlow allows us to speed up this processing.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7b378",
   "metadata": {},
   "source": [
    "## The solution: GPUs and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fddc371",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "In addition to being a powerful library for machine learning, TensorFlow allows you to train the created model using GPUs, enhancing and accelerating the training process. As we will see later, the performance gain when training a TensorFlow model on a GPU is enormous because GPUs are designed with thousands of processing cores, which allow the execution of many simultaneous operations. This is especially beneficial for matrix calculations, which are fundamental in machine learning algorithms such as neural networks.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf4e20-c662-4b55-afb1-3a72692d53b7",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "##  ☆ Challenge: Zoo breakout!☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a32ad3-6702-49ec-b03e-dd5f6be83cd1",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    Recently, an unexpected incident occurred at the local zoo, <b>Orange Grove Zoo</b>: all the animals escaped from their enclosures and are now roaming freely. To deal with this situation, we need your help locating and classifying the escaped animals, distinguishing each animal class, and identifying possible vehicles in the same environment.\n",
    "</p>\n",
    "<p style='text-align: justify;'> \n",
    "You have been assigned as the person responsible for developing a computer vision system capable of identifying and classifying the escaped animals and identifying the presence of vehicles in the images. We will use the CIFAR-10 dataset and the TensorFlow library to train a deep-learning model for this challenge.\n",
    "</p>\n",
    "CIFAR-10 and CIFAR-100 datasets comprehensively collect $32$x$32$ pixel images grouped into $10$ distinct classes.\n",
    "\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-10 consists of $60,000$ images, each belonging to one of the ten classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. This dataset offers a diverse set of images representing everyday objects.\n",
    "\n",
    "- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-100 expands upon the CIFAR-10 concept, containing 60,000 images as well. However, it introduces a more challenging task by categorizing images into 100 classes. These classes include various subcategories such as fruits, animals, vehicles, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac15552-86f2-42e2-a62d-ad0b875d46a0",
   "metadata": {
    "id": "X9pJ2tDOCaN6"
   },
   "source": [
    "a) **Create** deep neural network model utilizing the TensorFlow library for the classification of animals and vehicles on a GPU environment using the CIFAR-10 dataset.\n",
    "\n",
    "b) **Conduct** a comparative analysis between models trained on a CPU and GPU to highlight disparities in results.\n",
    "\n",
    "c) Now, use the CIFAR-100 dataset for the classification of animals and vehicles on a GPU. Would it be a good decision to use a GPU or CPU environment for the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3fab8-7a7d-4977-aa9f-3fbc73eb5ec0",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution for `CIFAR-10` using TensorFlow on GPU ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983edbde",
   "metadata": {},
   "source": [
    "#### ⊗ Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f0f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 19:59:40.414019: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-15 19:59:40.982429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fc965",
   "metadata": {},
   "source": [
    "#### ⊗ Verify the devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d046e",
   "metadata": {},
   "source": [
    "It is very important, before trying to execute anything on any device, to verify if it is available and if TensorFlow can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5ad9f",
   "metadata": {},
   "source": [
    "#####  Checking the environmental availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49480c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 19:59:41.674834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-15 19:59:41.693354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-15 19:59:41.693492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adb41f",
   "metadata": {},
   "source": [
    "#### ⊗ Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d0b28",
   "metadata": {},
   "source": [
    "Now we need to download the CIFAR-10 dataset to be able to make predictions. This dataset is a set of labeled images, meaning that each image already has a known label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c34a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2746c",
   "metadata": {},
   "source": [
    "#### ⊗ Normalizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c993dd",
   "metadata": {},
   "source": [
    "After downloading the entire set of images, we need to normalize them so that we can use them in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07245e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing pixel values to the [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136107e",
   "metadata": {},
   "source": [
    "#### ⊗ Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a977c7",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    " Below we have the training function with model creation and model compilation. Notice that we need to do the creation and compilation together with the training because we need to set in which device everything will be done. We need to do this because if we don't set the device to create and compile the model, the TensorFlow will choose the faster device, in this case, the GPU, so if we try to use the CPU to train the model, it will fail because the model will be created on the GPU. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375da0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, train_images, train_labels):\n",
    "    with tf.device(device):\n",
    "        \n",
    "        # Creating the CNN model\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(train_images, train_labels, epochs=10, \n",
    "                            validation_data=(test_images, test_labels), verbose=1)\n",
    "        end_time = time.time()\n",
    "    \n",
    "    return history, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c694e7d",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> The next step is to perform the model training. Note that in the step below, we will use the GPU to train the model and then the CPU to train and compare their execution times. (Depending on the GPU and CPU of your machine, this step may take some time). </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279b2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 20:11:16.301335: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2023-09-15 20:11:16.904010: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 2ms/step - loss: 1.5179 - accuracy: 0.4464 - val_loss: 1.3683 - val_accuracy: 0.5228\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1376 - accuracy: 0.5972 - val_loss: 1.0770 - val_accuracy: 0.6217\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.9832 - accuracy: 0.6540 - val_loss: 0.9725 - val_accuracy: 0.6612\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8881 - accuracy: 0.6889 - val_loss: 0.9027 - val_accuracy: 0.6864\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8137 - accuracy: 0.7155 - val_loss: 0.8819 - val_accuracy: 0.6991\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7516 - accuracy: 0.7375 - val_loss: 0.8704 - val_accuracy: 0.6995\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7027 - accuracy: 0.7551 - val_loss: 0.8221 - val_accuracy: 0.7194\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6605 - accuracy: 0.7673 - val_loss: 0.8430 - val_accuracy: 0.7146\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6198 - accuracy: 0.7826 - val_loss: 0.8321 - val_accuracy: 0.7188\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5790 - accuracy: 0.7974 - val_loss: 0.9028 - val_accuracy: 0.7064\n",
      "Training time on GPU: 37.23 seconds\n"
     ]
    }
   ],
   "source": [
    "gpu_history, gpu_time = train_model('/GPU:0', train_images, train_labels)\n",
    "print(f\"Training time on GPU: {gpu_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64666e10-02ff-4d6c-aa01-5b07f8d839d6",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution `CIFAR-100` using TensorFlow on CPU and GPU ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b516ea9-f290-48f3-9a1c-1d27dfe8fc40",
   "metadata": {},
   "source": [
    "#### ⊗ Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957c8134-f1af-461f-bcb6-04bf6fd3df37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 09:12:54.232584: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-16 09:12:54.735235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febc504-4ebe-4bb6-8f6c-c824026d568e",
   "metadata": {},
   "source": [
    "#### ⊗ Verify the devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df68d65-eaf6-4410-8ac1-1966b6b807c9",
   "metadata": {},
   "source": [
    "It is very important, before trying to execute anything on any device, to verify if it is available and if TensorFlow can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952650d-c543-4377-80d8-9acc349847d1",
   "metadata": {},
   "source": [
    "#####  Checking the environmental availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f562ecf4-18ab-4d8e-9069-f5ae649c35c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU device:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "GPU device:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "print(f\"CPU device: \", tf.config.list_physical_devices('CPU'))\n",
    "print(f\"GPU device: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231953fc-3a5a-4815-9bb9-e36da4ee6c03",
   "metadata": {},
   "source": [
    "#### ⊗ Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e871e-c674-45bc-80f0-95b92eacc173",
   "metadata": {},
   "source": [
    "Now we need to download the CIFAR-100 dataset to be able to make predictions. This dataset is a labeled images, meaning that each image to be loaded already has a known label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dc3ef2-a385-4e4b-bc61-9338eac7733d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the CIFAR-100 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea90a61-5c93-4ab2-8881-9333d4a7eced",
   "metadata": {},
   "source": [
    "#### ⊗ Normalizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa4126-0a2c-45b6-b93c-0912581f20d0",
   "metadata": {},
   "source": [
    "After downloading the entire set of images, we need to normalize them so that we can use them in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97aba15-fe1c-463a-814c-df82daa15b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing pixel values to the [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e061fe0-da7a-4e34-912e-29b17212eb34",
   "metadata": {},
   "source": [
    "#### ⊗ Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7451a-a8e4-46b5-8f11-cf50e8051030",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    " Below we have the training function with model creation and model compilation. Notice that we need to get the creation and compilation together with the training because we need to set in which device everything will be done. We need to do this because if we don't set the device to create and compile the model, the TensorFlow will choose the faster device, in this case, the GPU, so if we try to use the CPU to train the model, it will fail because the model will be created on the GPU. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e269f4-3312-47a8-a4a8-876b5244f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, train_images, train_labels):\n",
    "    with tf.device(device):\n",
    "        \n",
    "        # Creating the CNN model\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(100)\n",
    "        ])\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(train_images, train_labels, epochs=100, \n",
    "                            validation_data=(test_images, test_labels), verbose=1)\n",
    "        end_time = time.time()\n",
    "    \n",
    "    return history, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b4655-aaa5-48c9-84de-e8c6c4bbe4a1",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    The next step is to train the model. Note that in the step below we will use the CPU to train the model. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d66c50-1b15-4115-8312-04e4705af6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  21/1563 [..............................] - ETA: 7s - loss: 4.6106 - accuracy: 0.0134     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 09:24:48.049931: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x431fd560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-16 09:24:48.049972: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 9s 5ms/step - loss: 3.9819 - accuracy: 0.0892 - val_loss: 3.5132 - val_accuracy: 0.1664\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.3266 - accuracy: 0.1957 - val_loss: 3.1569 - val_accuracy: 0.2317\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.0399 - accuracy: 0.2515 - val_loss: 2.9831 - val_accuracy: 0.2637\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.8534 - accuracy: 0.2866 - val_loss: 2.8763 - val_accuracy: 0.2859\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.7151 - accuracy: 0.3141 - val_loss: 2.7670 - val_accuracy: 0.3162\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.6049 - accuracy: 0.3366 - val_loss: 2.7405 - val_accuracy: 0.3187\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5158 - accuracy: 0.3530 - val_loss: 2.6924 - val_accuracy: 0.3225\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4411 - accuracy: 0.3677 - val_loss: 2.6410 - val_accuracy: 0.3413\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3766 - accuracy: 0.3824 - val_loss: 2.6240 - val_accuracy: 0.3394\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3215 - accuracy: 0.3940 - val_loss: 2.5797 - val_accuracy: 0.3484\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2685 - accuracy: 0.4025 - val_loss: 2.5684 - val_accuracy: 0.3489\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2232 - accuracy: 0.4133 - val_loss: 2.5931 - val_accuracy: 0.3458\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1830 - accuracy: 0.4213 - val_loss: 2.5507 - val_accuracy: 0.3579\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1397 - accuracy: 0.4332 - val_loss: 2.5500 - val_accuracy: 0.3588\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0992 - accuracy: 0.4412 - val_loss: 2.5538 - val_accuracy: 0.3650\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0716 - accuracy: 0.4456 - val_loss: 2.5761 - val_accuracy: 0.3617\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0346 - accuracy: 0.4530 - val_loss: 2.5588 - val_accuracy: 0.3607\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0033 - accuracy: 0.4625 - val_loss: 2.5718 - val_accuracy: 0.3589\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9742 - accuracy: 0.4699 - val_loss: 2.5950 - val_accuracy: 0.3679\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9389 - accuracy: 0.4774 - val_loss: 2.6387 - val_accuracy: 0.3587\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9122 - accuracy: 0.4801 - val_loss: 2.6010 - val_accuracy: 0.3633\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8871 - accuracy: 0.4872 - val_loss: 2.6700 - val_accuracy: 0.3537\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8559 - accuracy: 0.4942 - val_loss: 2.6605 - val_accuracy: 0.3561\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8361 - accuracy: 0.4990 - val_loss: 2.6918 - val_accuracy: 0.3612\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8131 - accuracy: 0.5034 - val_loss: 2.7156 - val_accuracy: 0.3553\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7840 - accuracy: 0.5082 - val_loss: 2.7185 - val_accuracy: 0.3575\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7651 - accuracy: 0.5131 - val_loss: 2.7384 - val_accuracy: 0.3555\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7456 - accuracy: 0.5188 - val_loss: 2.7690 - val_accuracy: 0.3547\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7271 - accuracy: 0.5218 - val_loss: 2.7920 - val_accuracy: 0.3506\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7046 - accuracy: 0.5278 - val_loss: 2.7823 - val_accuracy: 0.3585\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6905 - accuracy: 0.5279 - val_loss: 2.7915 - val_accuracy: 0.3528\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6761 - accuracy: 0.5330 - val_loss: 2.9449 - val_accuracy: 0.3422\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6510 - accuracy: 0.5405 - val_loss: 2.8677 - val_accuracy: 0.3543\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6340 - accuracy: 0.5429 - val_loss: 2.9118 - val_accuracy: 0.3447\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6263 - accuracy: 0.5453 - val_loss: 2.9629 - val_accuracy: 0.3418\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6112 - accuracy: 0.5511 - val_loss: 2.9245 - val_accuracy: 0.3499\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5929 - accuracy: 0.5536 - val_loss: 2.9579 - val_accuracy: 0.3342\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5785 - accuracy: 0.5545 - val_loss: 3.0295 - val_accuracy: 0.3409\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5629 - accuracy: 0.5589 - val_loss: 3.0916 - val_accuracy: 0.3361\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5457 - accuracy: 0.5633 - val_loss: 3.0772 - val_accuracy: 0.3384\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5320 - accuracy: 0.5652 - val_loss: 3.1076 - val_accuracy: 0.3449\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5211 - accuracy: 0.5666 - val_loss: 3.1285 - val_accuracy: 0.3322\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5036 - accuracy: 0.5703 - val_loss: 3.2043 - val_accuracy: 0.3351\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4957 - accuracy: 0.5753 - val_loss: 3.1882 - val_accuracy: 0.3351\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4860 - accuracy: 0.5744 - val_loss: 3.1502 - val_accuracy: 0.3332\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4714 - accuracy: 0.5778 - val_loss: 3.1911 - val_accuracy: 0.3364\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4549 - accuracy: 0.5826 - val_loss: 3.2432 - val_accuracy: 0.3379\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4386 - accuracy: 0.5876 - val_loss: 3.3259 - val_accuracy: 0.3272\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4332 - accuracy: 0.5883 - val_loss: 3.3070 - val_accuracy: 0.3276\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4156 - accuracy: 0.5926 - val_loss: 3.3298 - val_accuracy: 0.3239\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4063 - accuracy: 0.5948 - val_loss: 3.3854 - val_accuracy: 0.3263\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4002 - accuracy: 0.5972 - val_loss: 3.4569 - val_accuracy: 0.3286\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3880 - accuracy: 0.5972 - val_loss: 3.4731 - val_accuracy: 0.3246\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3786 - accuracy: 0.6014 - val_loss: 3.4520 - val_accuracy: 0.3224\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3739 - accuracy: 0.6011 - val_loss: 3.4857 - val_accuracy: 0.3217\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3609 - accuracy: 0.6049 - val_loss: 3.5502 - val_accuracy: 0.3214\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3583 - accuracy: 0.6040 - val_loss: 3.6208 - val_accuracy: 0.3179\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3421 - accuracy: 0.6108 - val_loss: 3.7040 - val_accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3413 - accuracy: 0.6095 - val_loss: 3.6031 - val_accuracy: 0.3215\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3225 - accuracy: 0.6123 - val_loss: 3.6826 - val_accuracy: 0.3180\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3164 - accuracy: 0.6145 - val_loss: 3.6124 - val_accuracy: 0.3158\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3080 - accuracy: 0.6167 - val_loss: 3.7509 - val_accuracy: 0.3079\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3106 - accuracy: 0.6174 - val_loss: 3.6610 - val_accuracy: 0.3169\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3047 - accuracy: 0.6149 - val_loss: 3.6842 - val_accuracy: 0.3195\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2879 - accuracy: 0.6239 - val_loss: 3.8023 - val_accuracy: 0.3112\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2885 - accuracy: 0.6230 - val_loss: 3.7862 - val_accuracy: 0.3188\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2758 - accuracy: 0.6233 - val_loss: 3.8191 - val_accuracy: 0.3142\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2735 - accuracy: 0.6254 - val_loss: 3.8981 - val_accuracy: 0.3139\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2667 - accuracy: 0.6254 - val_loss: 3.9225 - val_accuracy: 0.3128\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2617 - accuracy: 0.6275 - val_loss: 3.9302 - val_accuracy: 0.3095\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2579 - accuracy: 0.6299 - val_loss: 3.8839 - val_accuracy: 0.3101\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2505 - accuracy: 0.6318 - val_loss: 3.9681 - val_accuracy: 0.3083\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2405 - accuracy: 0.6319 - val_loss: 3.9533 - val_accuracy: 0.3121\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2316 - accuracy: 0.6359 - val_loss: 4.0000 - val_accuracy: 0.3135\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2299 - accuracy: 0.6356 - val_loss: 4.0859 - val_accuracy: 0.3129\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2176 - accuracy: 0.6393 - val_loss: 4.0583 - val_accuracy: 0.3086\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2152 - accuracy: 0.6397 - val_loss: 4.0663 - val_accuracy: 0.3103\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2126 - accuracy: 0.6410 - val_loss: 4.0706 - val_accuracy: 0.3085\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2121 - accuracy: 0.6400 - val_loss: 4.1506 - val_accuracy: 0.3063\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2016 - accuracy: 0.6424 - val_loss: 4.0972 - val_accuracy: 0.3116\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1940 - accuracy: 0.6473 - val_loss: 4.2939 - val_accuracy: 0.3007\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1824 - accuracy: 0.6481 - val_loss: 4.2251 - val_accuracy: 0.3059\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1842 - accuracy: 0.6479 - val_loss: 4.2890 - val_accuracy: 0.3107\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1807 - accuracy: 0.6491 - val_loss: 4.2186 - val_accuracy: 0.3066\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1873 - accuracy: 0.6447 - val_loss: 4.2313 - val_accuracy: 0.3098\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1771 - accuracy: 0.6480 - val_loss: 4.3118 - val_accuracy: 0.3090\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1573 - accuracy: 0.6538 - val_loss: 4.4253 - val_accuracy: 0.3039\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1634 - accuracy: 0.6505 - val_loss: 4.3062 - val_accuracy: 0.3061\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1530 - accuracy: 0.6563 - val_loss: 4.5677 - val_accuracy: 0.3010\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1595 - accuracy: 0.6514 - val_loss: 4.4426 - val_accuracy: 0.3083\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1438 - accuracy: 0.6575 - val_loss: 4.4276 - val_accuracy: 0.3047\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1520 - accuracy: 0.6562 - val_loss: 4.5023 - val_accuracy: 0.3078\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1492 - accuracy: 0.6542 - val_loss: 4.4660 - val_accuracy: 0.3059\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1439 - accuracy: 0.6572 - val_loss: 4.4674 - val_accuracy: 0.3044\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1353 - accuracy: 0.6587 - val_loss: 4.5444 - val_accuracy: 0.3003\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1390 - accuracy: 0.6584 - val_loss: 4.5544 - val_accuracy: 0.3069\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1335 - accuracy: 0.6605 - val_loss: 4.5173 - val_accuracy: 0.3006\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1250 - accuracy: 0.6619 - val_loss: 4.7405 - val_accuracy: 0.2973\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1128 - accuracy: 0.6647 - val_loss: 4.7210 - val_accuracy: 0.2940\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1219 - accuracy: 0.6613 - val_loss: 4.6433 - val_accuracy: 0.2976\n",
      "\n",
      "CPU Training time: 793.55 seconds or (13.23 minutes)\n"
     ]
    }
   ],
   "source": [
    "history, cpu_time = train_model('/CPU:0', train_images, train_labels)\n",
    "print(f\"\\nCPU Training time: {cpu_time:.2f} seconds or ({cpu_time / 60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020138db-d31a-4065-99ad-574da599db9e",
   "metadata": {},
   "source": [
    "Now we will perform the same training only using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a08c023-228b-4ded-86ac-656aa008649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 09:13:45.253909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30925 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:60:00.0, compute capability: 7.0\n",
      "2023-10-16 09:13:45.254927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30925 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "2023-10-16 09:13:45.255824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30925 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:88:00.0, compute capability: 7.0\n",
      "2023-10-16 09:13:45.256247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30925 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 09:13:53.670098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-16 09:13:58.179113: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fbb9b3a9700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-16 09:13:58.179143: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-10-16 09:13:58.179148: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-10-16 09:13:58.179152: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-10-16 09:13:58.179156: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-10-16 09:13:58.184334: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-16 09:13:58.365105: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 19s 3ms/step - loss: 3.9534 - accuracy: 0.0922 - val_loss: 3.4394 - val_accuracy: 0.1770\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 3.2221 - accuracy: 0.2163 - val_loss: 3.0993 - val_accuracy: 0.2438\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.9321 - accuracy: 0.2718 - val_loss: 2.9042 - val_accuracy: 0.2769\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.7307 - accuracy: 0.3098 - val_loss: 2.7362 - val_accuracy: 0.3168\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.5833 - accuracy: 0.3401 - val_loss: 2.6788 - val_accuracy: 0.3202\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.4728 - accuracy: 0.3634 - val_loss: 2.6361 - val_accuracy: 0.3347\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.3771 - accuracy: 0.3856 - val_loss: 2.6183 - val_accuracy: 0.3422\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.3020 - accuracy: 0.4017 - val_loss: 2.5928 - val_accuracy: 0.3499\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.2316 - accuracy: 0.4126 - val_loss: 2.5406 - val_accuracy: 0.3660\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1711 - accuracy: 0.4283 - val_loss: 2.5160 - val_accuracy: 0.3707\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1143 - accuracy: 0.4416 - val_loss: 2.5956 - val_accuracy: 0.3548\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0652 - accuracy: 0.4484 - val_loss: 2.5254 - val_accuracy: 0.3707\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0162 - accuracy: 0.4622 - val_loss: 2.5881 - val_accuracy: 0.3623\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9766 - accuracy: 0.4669 - val_loss: 2.5621 - val_accuracy: 0.3717\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9369 - accuracy: 0.4781 - val_loss: 2.6400 - val_accuracy: 0.3621\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9007 - accuracy: 0.4849 - val_loss: 2.6662 - val_accuracy: 0.3560\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8688 - accuracy: 0.4904 - val_loss: 2.6379 - val_accuracy: 0.3696\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8330 - accuracy: 0.5013 - val_loss: 2.6980 - val_accuracy: 0.3546\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8073 - accuracy: 0.5044 - val_loss: 2.6590 - val_accuracy: 0.3657\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7777 - accuracy: 0.5104 - val_loss: 2.7080 - val_accuracy: 0.3615\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7426 - accuracy: 0.5169 - val_loss: 2.7782 - val_accuracy: 0.3538\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7197 - accuracy: 0.5261 - val_loss: 2.8206 - val_accuracy: 0.3538\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6962 - accuracy: 0.5293 - val_loss: 2.8022 - val_accuracy: 0.3535\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6693 - accuracy: 0.5364 - val_loss: 2.7869 - val_accuracy: 0.3600\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6439 - accuracy: 0.5399 - val_loss: 2.8932 - val_accuracy: 0.3547\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6171 - accuracy: 0.5466 - val_loss: 2.8882 - val_accuracy: 0.3535\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6027 - accuracy: 0.5499 - val_loss: 2.9009 - val_accuracy: 0.3537\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5736 - accuracy: 0.5586 - val_loss: 2.9594 - val_accuracy: 0.3524\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5473 - accuracy: 0.5618 - val_loss: 3.0172 - val_accuracy: 0.3513\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5228 - accuracy: 0.5691 - val_loss: 3.0996 - val_accuracy: 0.3379\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5072 - accuracy: 0.5732 - val_loss: 3.1028 - val_accuracy: 0.3265\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4849 - accuracy: 0.5781 - val_loss: 3.0664 - val_accuracy: 0.3495\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4648 - accuracy: 0.5817 - val_loss: 3.1343 - val_accuracy: 0.3461\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4451 - accuracy: 0.5863 - val_loss: 3.1684 - val_accuracy: 0.3428\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4222 - accuracy: 0.5934 - val_loss: 3.2421 - val_accuracy: 0.3417\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4187 - accuracy: 0.5933 - val_loss: 3.2054 - val_accuracy: 0.3394\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3966 - accuracy: 0.5993 - val_loss: 3.2129 - val_accuracy: 0.3407\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3857 - accuracy: 0.6019 - val_loss: 3.3282 - val_accuracy: 0.3412\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3637 - accuracy: 0.6061 - val_loss: 3.3721 - val_accuracy: 0.3392\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3496 - accuracy: 0.6092 - val_loss: 3.3728 - val_accuracy: 0.3421\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3355 - accuracy: 0.6142 - val_loss: 3.4011 - val_accuracy: 0.3381\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3196 - accuracy: 0.6182 - val_loss: 3.4395 - val_accuracy: 0.3278\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3135 - accuracy: 0.6180 - val_loss: 3.5158 - val_accuracy: 0.3343\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2979 - accuracy: 0.6242 - val_loss: 3.5115 - val_accuracy: 0.3324\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2773 - accuracy: 0.6271 - val_loss: 3.5756 - val_accuracy: 0.3309\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2730 - accuracy: 0.6268 - val_loss: 3.5962 - val_accuracy: 0.3337\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2542 - accuracy: 0.6340 - val_loss: 3.6749 - val_accuracy: 0.3298\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2457 - accuracy: 0.6341 - val_loss: 3.6614 - val_accuracy: 0.3249\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2376 - accuracy: 0.6371 - val_loss: 3.7630 - val_accuracy: 0.3283\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2258 - accuracy: 0.6392 - val_loss: 3.8323 - val_accuracy: 0.3263\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2104 - accuracy: 0.6432 - val_loss: 3.8620 - val_accuracy: 0.3282\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1997 - accuracy: 0.6447 - val_loss: 3.8259 - val_accuracy: 0.3275\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1922 - accuracy: 0.6475 - val_loss: 3.8983 - val_accuracy: 0.3200\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1793 - accuracy: 0.6520 - val_loss: 3.9475 - val_accuracy: 0.3235\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1694 - accuracy: 0.6545 - val_loss: 3.9504 - val_accuracy: 0.3227\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1627 - accuracy: 0.6535 - val_loss: 4.0506 - val_accuracy: 0.3205\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1615 - accuracy: 0.6545 - val_loss: 3.9690 - val_accuracy: 0.3158\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1489 - accuracy: 0.6576 - val_loss: 4.0775 - val_accuracy: 0.3200\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1313 - accuracy: 0.6631 - val_loss: 4.1379 - val_accuracy: 0.3189\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1300 - accuracy: 0.6640 - val_loss: 4.0953 - val_accuracy: 0.3118\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1165 - accuracy: 0.6654 - val_loss: 4.1572 - val_accuracy: 0.3157\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1119 - accuracy: 0.6660 - val_loss: 4.2073 - val_accuracy: 0.3189\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1056 - accuracy: 0.6677 - val_loss: 4.2687 - val_accuracy: 0.3188\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1019 - accuracy: 0.6685 - val_loss: 4.2978 - val_accuracy: 0.3165\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0984 - accuracy: 0.6686 - val_loss: 4.4104 - val_accuracy: 0.3143\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0893 - accuracy: 0.6721 - val_loss: 4.3928 - val_accuracy: 0.3170\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0729 - accuracy: 0.6781 - val_loss: 4.3745 - val_accuracy: 0.3092\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0789 - accuracy: 0.6730 - val_loss: 4.5234 - val_accuracy: 0.3127\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0673 - accuracy: 0.6778 - val_loss: 4.3957 - val_accuracy: 0.3148\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0614 - accuracy: 0.6805 - val_loss: 4.5851 - val_accuracy: 0.3049\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0563 - accuracy: 0.6810 - val_loss: 4.6282 - val_accuracy: 0.3086\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0496 - accuracy: 0.6828 - val_loss: 4.6083 - val_accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0506 - accuracy: 0.6802 - val_loss: 4.6487 - val_accuracy: 0.3120\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0430 - accuracy: 0.6830 - val_loss: 4.6758 - val_accuracy: 0.3070\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0378 - accuracy: 0.6835 - val_loss: 4.6363 - val_accuracy: 0.3051\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0285 - accuracy: 0.6860 - val_loss: 4.6699 - val_accuracy: 0.3030\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0277 - accuracy: 0.6874 - val_loss: 4.8198 - val_accuracy: 0.3149\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0161 - accuracy: 0.6906 - val_loss: 4.7324 - val_accuracy: 0.3069\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0078 - accuracy: 0.6921 - val_loss: 4.8526 - val_accuracy: 0.3081\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0073 - accuracy: 0.6924 - val_loss: 4.8894 - val_accuracy: 0.3038\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9982 - accuracy: 0.6941 - val_loss: 4.9335 - val_accuracy: 0.3064\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9997 - accuracy: 0.6948 - val_loss: 4.8808 - val_accuracy: 0.3077\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9928 - accuracy: 0.6959 - val_loss: 4.9232 - val_accuracy: 0.3056\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9872 - accuracy: 0.6980 - val_loss: 4.9312 - val_accuracy: 0.3023\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9847 - accuracy: 0.6980 - val_loss: 5.0675 - val_accuracy: 0.3003\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9839 - accuracy: 0.6986 - val_loss: 5.0923 - val_accuracy: 0.3025\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9774 - accuracy: 0.6988 - val_loss: 5.2242 - val_accuracy: 0.2975\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9658 - accuracy: 0.7036 - val_loss: 5.1344 - val_accuracy: 0.2981\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9721 - accuracy: 0.7024 - val_loss: 5.3160 - val_accuracy: 0.3069\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9683 - accuracy: 0.7017 - val_loss: 5.2336 - val_accuracy: 0.2946\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9514 - accuracy: 0.7045 - val_loss: 5.2056 - val_accuracy: 0.2999\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9599 - accuracy: 0.7047 - val_loss: 5.2071 - val_accuracy: 0.3098\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9463 - accuracy: 0.7081 - val_loss: 5.2805 - val_accuracy: 0.2994\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9469 - accuracy: 0.7075 - val_loss: 5.3430 - val_accuracy: 0.2913\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9434 - accuracy: 0.7091 - val_loss: 5.4364 - val_accuracy: 0.3033\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9443 - accuracy: 0.7099 - val_loss: 5.3514 - val_accuracy: 0.2956\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9385 - accuracy: 0.7126 - val_loss: 5.3424 - val_accuracy: 0.2967\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9380 - accuracy: 0.7118 - val_loss: 5.4861 - val_accuracy: 0.2979\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9257 - accuracy: 0.7110 - val_loss: 5.4694 - val_accuracy: 0.2991\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9358 - accuracy: 0.7101 - val_loss: 5.5537 - val_accuracy: 0.2890\n",
      "\n",
      "GPU Training time: 443.74 seconds or (7.40 minutes)\n"
     ]
    }
   ],
   "source": [
    "history, gpu_time = train_model('/GPU:0', train_images, train_labels)\n",
    "print(f\"\\nGPU Training time: {gpu_time:.2f} seconds or ({gpu_time / 60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd2cc5-78a3-4c2b-80d3-f05113f4b505",
   "metadata": {},
   "source": [
    "Now we will evaluate the speedup by comparing the GPU and CPU execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b3db5c-af0f-4f09-86fe-ecf23de9d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speedup: 1.79X\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSpeedup:{cpu_time / gpu_time: .2f}X\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3689f6-fd46-4d9f-b72e-651ad7d3f4fb",
   "metadata": {},
   "source": [
    "### Comments about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf1b32",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "We explored training neural networks with TensorFlow, comparing CPU and GPU performance on the CIFAR-10 and CIFAR-100 dataset using 10 epochs. When training with CIFAR-10 and utilizing the CPU, and GPU environments, the process can be executed in approximately:\n",
    "</p>\n",
    "\n",
    "|  TensorFlow |      CIFAR-10    |  CIFAR-100 |\n",
    "|----------|:-------------:      |-----------:|\n",
    "| CPU         |  811.17          |   0,000.00|\n",
    "| GPU         |  37.23           |   00.00 |\n",
    "| Speedup     |  21.78X          |   0.00 |\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "This outcome illustrates that the GPU has achieved nearly a <b>Speedup of 7X</b> compared to the CPU when running with 10 epochs in the algorithm with the highest computational cost (CIFAR-100). Thanks to its parallel computing capabilities, the GPU has substantially enhanced the training speed, which is particularly advantageous for handling extensive data and intricate models in deep learning.\n",
    "</p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f43b0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook we have shown: \n",
    "\n",
    "- Install and use TensorFlow using GPU environments,\n",
    "- Comparative performance tests between CPU and GPU on model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e8dad",
   "metadata": {},
   "source": [
    "## Clear the memory\n",
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3945a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52915-f34b-480a-ac98-dc48f82bd007",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebb05e",
   "metadata": {},
   "source": [
    "In this section, you learned how to use TensorFlow in a simple example using a GPU environment. In the next section, you will learn about other applications in which those devices can be pretty useful, in the notebbok [_03-hpc-simulations-pytorch.ipynb_](03-hpc-simulations-pytorch.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
